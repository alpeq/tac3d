{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch as snn\n",
    "import snntorch.spikeplot as splt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from snntorch import spikegen, surrogate, utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from IPython.display import HTML\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net_default = {\n",
    "    'beta': 0.9,\n",
    "    'kernel_size': 5,\n",
    "    'num_steps': 100,\n",
    "    'rf_channels': 16,\n",
    "    'spike_grad': surrogate.fast_sigmoid(slope=25)\n",
    "}\n",
    "\n",
    "\n",
    "class TouchDataset(Dataset):\n",
    "    def __init__(self, filename, transform=None) -> None:\n",
    "        \"\"\"Constructor for TouchDataset.\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): File Name of the touch data.\n",
    "            transform (Compose, optional): Compose of transforms to apply on samples. Defaults to None.\n",
    "        \"\"\"\n",
    "        data = np.load(filename, allow_pickle=True)\n",
    "        sensordata = [np.array(data[k]['sensordata'], dtype=np.float32) for k in data.keys()]\n",
    "        orientation = [np.array(data[k]['orientations'], dtype=np.float32) for k in data.keys()]\n",
    "        self.sensordata, self.orientation = np.vstack(\n",
    "            sensordata), np.hstack(orientation)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.orientation)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.sensordata[index, :, :]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, self.orientation[index]\n",
    "\n",
    "\n",
    "class MinMaxScale(object):\n",
    "    def __init__(self, minVal, maxVal):\n",
    "        \"\"\"Initialize the transform to rescale the values into [minVal, maxVal].\n",
    "\n",
    "        Args:\n",
    "            minVal (float): Minimum value.\n",
    "            maxVal (float): Maximum value.\n",
    "        \"\"\"\n",
    "        self.min, self.max = minVal, maxVal\n",
    "\n",
    "    def __call__(self, x):\n",
    "        min_x, max_x = np.min(x), np.max(x)\n",
    "        if min_x >= max_x:\n",
    "            y = np.ones(x.shape, dtype=np.float32)*max_x\n",
    "        else:\n",
    "            y = (x - min_x)/(max_x - min_x)*(self.max - self.min) + self.min\n",
    "        return y\n",
    "\n",
    "\n",
    "class ToSpike(object):\n",
    "    def __init__(self, encoding='rate', **kwargs):\n",
    "        \"\"\"Initialize the spike generator.\n",
    "\n",
    "        Args:\n",
    "            encoding (str, optional): Spiking encoding options. Defaults to 'rate'.\n",
    "        \"\"\"\n",
    "        self._encodings = ['rate', 'latency', 'delta']\n",
    "        if encoding in self._encodings:\n",
    "            self.encoding = encoding\n",
    "        else:\n",
    "            self.encoding = self._encodings[0]\n",
    "        self.configs = kwargs\n",
    "        match self.encoding:\n",
    "            case 'rate':\n",
    "                default = {\n",
    "                    'num_steps': 100,\n",
    "                    'gain': 0.5\n",
    "                }\n",
    "            case 'latency':\n",
    "                deafult = {\n",
    "\n",
    "                }\n",
    "            case 'delta':\n",
    "                default = {\n",
    "                    'threshold': 4\n",
    "                }\n",
    "            case _:\n",
    "                default = {\n",
    "\n",
    "                }\n",
    "        self.configs = default | self.configs\n",
    "\n",
    "    def __call__(self, x):\n",
    "        match self.encoding:\n",
    "            case 'rate':\n",
    "                y = spikegen.rate(\n",
    "                    x,\n",
    "                    num_steps=self.configs['num_steps'],\n",
    "                    gain=self.configs['gain'])\n",
    "            case 'delta':\n",
    "                y = spikegen.delta(\n",
    "                    x,\n",
    "                    threshold=self.configs['threshold'])\n",
    "            case _:\n",
    "                y = x\n",
    "        return y\n",
    "\n",
    "\n",
    "class TacNet(nn.Module):\n",
    "    def __init__(self, dim_input, dim_output, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_output = dim_output\n",
    "        self.configs = kwargs | net_default\n",
    "\n",
    "        # Initialize Network\n",
    "        # autopep8: off\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=self.configs['rf_channels'], kernel_size=self.configs['kernel_size'], stride=1),\n",
    "                                 snn.Leaky(beta=self.configs['beta'], spike_grad=self.configs['spike_grad'], init_hidden=True),\n",
    "                                 nn.Conv2d(self.configs['rf_channels'], 32, 3),\n",
    "                                 nn.MaxPool2d(2),\n",
    "                                 snn.Leaky(beta=self.configs['beta'], spike_grad=self.configs['spike_grad'], init_hidden=True, output=True))\n",
    "        # autopep8: on\n",
    "        self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"Initialize the weights of the 1st hidden layer. Sample weights from a Gaussian process.\n",
    "        \"\"\"        \n",
    "        center = self.configs['kernel_size']//2\n",
    "        kernel = np.zeros(self.net[0].weight.shape)\n",
    "        kernel[:, :, center, center] = 1\n",
    "        kernel = gaussian_filter(kernel, sigma=center)\n",
    "        with torch.no_grad():\n",
    "            self.net[0].weight.copy_(torch.from_numpy(kernel))\n",
    "\n",
    "    def forward(self, num_steps, x):\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "        # resets hidden states for all LIF neurons in net\n",
    "        utils.reset(self.net)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            spk_out, mem_out = self.net(x)\n",
    "            spk_rec.append(spk_out)\n",
    "            mem_rec.append(mem_out)\n",
    "\n",
    "        return torch.stack(spk_rec), torch.stack(mem_rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Touch Dataset with Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 wngfra.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "batch_size = 128\n",
    "num_steps = 100\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    MinMaxScale(0., 1.0),\n",
    "    transforms.ToTensor(),\n",
    "    ToSpike('rate'),\n",
    "])\n",
    "touch_dataset = TouchDataset('../data/touch.pkl', transform=transform)\n",
    "train_loader = DataLoader(touch_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = TacNet(1, 10).to(device)\n",
    "\n",
    "# Iterate through minibatches\n",
    "for train_data, train_target in train_loader:\n",
    "    train_data = train_data.to(device)\n",
    "    train_target = train_target.to(device)\n",
    "    \n",
    "    spk, mem = model(num_steps, train_data[:, 0, :, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b81b3919ee5f2218cc5f3be42eecb9a1fdcc9dc6e8f946db5ad2423192a42a92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
