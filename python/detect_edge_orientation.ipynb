{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# MuJoCo Robotic Simulation Generating Synthetic Data\n",
    "* Franka-Emika Panda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MUJOCO_GL=egl\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39metree\u001b[39;00m \u001b[39mimport\u001b[39;00m ElementTree \u001b[39mas\u001b[39;00m et\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmediapy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmedia\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m Rotation \u001b[39mas\u001b[39;00m R\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapy'"
     ]
    }
   ],
   "source": [
    "%env MUJOCO_GL = egl\n",
    "%matplotlib widget\n",
    "import os\n",
    "import pickle\n",
    "from multiprocessing import Lock, Pool\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Access to enums and MuJoCo library functions.\n",
    "from dm_control import mujoco\n",
    "from dm_control.mujoco.wrapper.mjbindings import mjlib\n",
    "from dm_control.utils import inverse_kinematics as ik\n",
    "from IPython.display import HTML, clear_output, display\n",
    "from PIL import Image\n",
    "from scipy.special import gamma\n",
    "\n",
    "# Rendering parameters\n",
    "dpi = 100\n",
    "framerate = 30  # (Hz)\n",
    "width, height = 1280, 720\n",
    "\n",
    "# IK solver parameters\n",
    "_MAX_STEPS = 100\n",
    "_TOL = 1e-12\n",
    "\n",
    "# Scene XML\n",
    "robot_xml = \"../models/panda_nohand.xml\"\n",
    "scene_xml = \"../models/scene.xml\"\n",
    "site_name = \"attachment_site\"\n",
    "reach_sites = [\"sharp_site\", \"round_site\", \"wedge_site\"]\n",
    "actuator_id = {\"sharp_site\": 1, \"round_site\": 2, \"wedge_site\": 3}\n",
    "joint_names = [\"joint{}\".format(i + 1) for i in range(7)]\n",
    "\n",
    "# Multiprocessing lock\n",
    "threaded = False\n",
    "if threaded:\n",
    "    lock = Lock()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## [Optional]Update The Scene XML File\n",
    "* [Mujoco XML Reference](https://mujoco.readthedocs.io/en/latest/XMLreference.html?highlight=site#body-site)\n",
    "* [The ElementTree XML API](https://docs.python.org/3/library/xml.etree.elementtree.html)\n",
    "\n",
    "### Tactile Sensor\n",
    "\n",
    "1. Sensor Pad \n",
    "* for visual only\n",
    "\n",
    "2. Collision Balls (mono-layer)\n",
    "* _M: (x-count, y-count)\n",
    "* geom_type: [sphere, capsule, ellipsoid, cylinder, box], “sphere”\n",
    "* dx: the distance between each site\n",
    "* offset: uniform distance to shift all sites\n",
    "\n",
    "3. Slide Joints\n",
    "* connect the balls to the pad\n",
    "* joint positions serve as sensory values\n",
    "* small time constant\n",
    "\n",
    "4. Tendons to Connect Balls\n",
    "* planar spring connection\n",
    "* creates contact-force distribution\n",
    "\n",
    "### Key Frames\n",
    "* Initial poses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robotic Simulation for Tactile Encoding Test\n",
    "\n",
    "* Synthetic data generation\n",
    "    - Check [models](../models/platform.xml) for edge types\n",
    "* Save sensor data and simulation\n",
    "    - [Sensordata](touch3edge.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(\n",
    "    scene_xml, site_name, target_name, joint_names, duration=2.0, rendered=True\n",
    "):\n",
    "    physics = mujoco.Physics.from_xml_path(scene_xml)\n",
    "    physics.reset(0)\n",
    "\n",
    "    omega = 4 * np.pi / duration * np.array([1, 1, 1])\n",
    "    ctrl = np.empty(10)\n",
    "    video = []\n",
    "    stream = []\n",
    "    orientations = []\n",
    "    control_site = physics.data.site(name=site_name)\n",
    "    target_site = physics.data.site(name=target_name)\n",
    "    target_quat = R.from_matrix(control_site.xmat.reshape((3,3))).as_quat()\n",
    "    target_xpos = target_site.xpos.copy()\n",
    "    target_xpos[2] -= 1e-3\n",
    "    smooth_factor = 0.5\n",
    "\n",
    "    # Simulate, saving video frames\n",
    "    while physics.data.time <= duration:\n",
    "        move_vec = (\n",
    "            (target_xpos - control_site.xpos)\n",
    "            * min(smooth_factor, physics.data.time)\n",
    "            / smooth_factor\n",
    "        )\n",
    "        # Compute the inverse kinematics\n",
    "        if np.linalg.norm(control_site.xpos - target_xpos) > _TOL:\n",
    "            result = ik.qpos_from_site_pose(\n",
    "                physics,\n",
    "                site_name,\n",
    "                target_pos=control_site.xpos + move_vec,\n",
    "                target_quat=target_quat,\n",
    "                joint_names=joint_names,\n",
    "                tol=_TOL,\n",
    "                max_steps=_MAX_STEPS,\n",
    "                inplace=False,\n",
    "            )\n",
    "            ctrl[:7] = result.qpos[:7]\n",
    "        ctrl[-3:] = omega * physics.data.time\n",
    "        physics.set_control(ctrl)\n",
    "        physics.step()\n",
    "\n",
    "        # Save sensordata when there is contact\n",
    "        if len(physics.data.contact) > 0:\n",
    "            sensordata = physics.data.sensordata.copy()\n",
    "            M = np.sqrt(sensordata.shape[0]).astype(int)\n",
    "            data = sensordata.reshape(M, M)\n",
    "            stream.append(data)\n",
    "            oris = physics.named.data.qpos[\n",
    "                \"rotator_joint%d\" % actuator_id[target_name]\n",
    "            ].copy()\n",
    "            orientations.append(oris)\n",
    "\n",
    "        # Save video frames\n",
    "        clear_output(wait=True)\n",
    "        print(\n",
    "            \"PID {} simulating {}. Progress: {:.1f}%\".format(\n",
    "                os.getpid(), target_name, physics.data.time / duration * 100\n",
    "            )\n",
    "        )\n",
    "        if rendered and len(video) < physics.data.time * framerate:\n",
    "            if threaded:\n",
    "                lock.acquire()\n",
    "            pixels = physics.render(camera_id=\"prospective\", width=width, height=height)\n",
    "            if threaded:\n",
    "                lock.release()\n",
    "            video.append(pixels.copy())\n",
    "\n",
    "    return target_name, video, stream, orientations\n",
    "\n",
    "\n",
    "ds = dict()\n",
    "\n",
    "for rs in reach_sites:\n",
    "    label, video, stream, orientations = gen_dataset(\n",
    "        scene_xml, site_name, rs, joint_names, duration=7.0, rendered=True\n",
    "    )\n",
    "    ds[label] = {\"sensordata\": stream, \"orientations\": orientations}\n",
    "    media.write_video(\"../data/\" + label + \".mp4\", video, fps=30)\n",
    "\n",
    "with open(\"../data/touch.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(url=\"../docs/round_site.mp4\", width=720)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualize Tactile Signals\n",
    "* $15 \\times 15$ taxels simulated by damped spring-linked particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from TouchDataset import TouchDataset\n",
    "\n",
    "dataset = TouchDataset(\"../data/touch.pkl\", noise_scale=5e-2, flatten=False)\n",
    "image = Image.open(\"../docs/soft_contact.png\")\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax0 = plt.subplot(121)\n",
    "ax0.imshow(image)\n",
    "ax1 = plt.subplot(133)\n",
    "ax1.imshow(dataset[1000][0])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unsupervised Edge Orientation Classifier\n",
    "1. 3-Layer Layer Spiking Neural Network\n",
    "2. Binary input layer\n",
    "3. Random receptive field - 25 neurons\n",
    "4. Edge Orientation Output - 36 neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network structure and hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from brian2 import *\n",
    "\n",
    "events = {\"event3\": [\"increase_threshold\", \"v > v_th\", \"v_th += delta_theta*rand()\"]}\n",
    "\n",
    "params = {\n",
    "    # Model constants\n",
    "    \"C_mem\": 200 * pF,  # Membrane capacitance\n",
    "    \"delta_theta\": 3 * mV,  # Adaptive threshold incremental scale\n",
    "    \"g_l\": 10 * nS,  # Leak conductance\n",
    "    \"J_C\": 1,  # Scale of the calcium variable\n",
    "    \"tau_c\": 60 * ms,  # Calcium variable time constant\n",
    "    \"tau_e\": 10 * ms,  # Excitatory synaptic time constant\n",
    "    \"tau_i\": 10 * ms,  # Inhibitory synaptic time constant\n",
    "    \"tau_r\": 5 * ms,  # Refractory period\n",
    "    \"tau_theta\": 5 * ms,  # Adaptive threshold time constant\n",
    "    \"V_ir\": -80 * mV,  # Inhibitory reverse potential\n",
    "    \"V_res\": -65 * mV,  # Resting potential\n",
    "    \"V_theta\": -55 * mV,  # Spiking threshold\n",
    "    \"w_e\": 20 * nS,  # Excitatory conductance increment\n",
    "    \"w_i\": 30 * nS,  # Inhibitory conductance increment\n",
    "    \"X_max\": 1,  # Synaptic variable maximum\n",
    "    \"X_min\": 0,  # Synaptic variable minimum\n",
    "    # Simulation parameters\n",
    "    \"defaultclock.dt\": 0.1 * ms,  # Time step\n",
    "}\n",
    "\n",
    "# Thresholds and plasticity parameters\n",
    "params[\"a\"] = 0.1 * params[\"X_max\"]\n",
    "params[\"b\"] = 0.1 * params[\"X_max\"]\n",
    "params[\"alpha\"] = 3.5 * params[\"X_max\"] * Hz\n",
    "params[\"beta\"] = 3.5 * params[\"X_max\"] * Hz\n",
    "params[\"theta_hup\"] = 12 * params[\"J_C\"]\n",
    "params[\"theta_lup\"] = 3 * params[\"J_C\"]\n",
    "params[\"theta_hdown\"] = 4 * params[\"J_C\"]\n",
    "params[\"theta_ldown\"] = 3 * params[\"J_C\"]\n",
    "params[\"theta_v\"] = 0.8 * params[\"V_theta\"]\n",
    "params[\"theta_X\"] = 0.5 * params[\"X_max\"]\n",
    "params[\"learning_switch\"] = 1\n",
    "\n",
    "eqs = {\n",
    "    # Neuronal models\n",
    "    \"L1\": \"\"\"\n",
    "        dv/dt = (g_l*(V_res - v) + I(t,i))/C_mem : volt (unless refractory)\n",
    "        x : 1\n",
    "        y : 1\n",
    "        \"\"\",\n",
    "    \"L2\": \"\"\"\n",
    "        dv/dt = (g_l*(V_res - v) - g_e*v + learning_switch*g_i*(V_ir - v))/C_mem : volt (unless refractory)\n",
    "        dg_e/dt = -g_e/tau_e : siemens\n",
    "        dg_i/dt = -g_i/tau_i : siemens\n",
    "        dv_th/dt = (V_theta - v_th)/tau_theta : volt\n",
    "        sum_w : 1\n",
    "        \"\"\",\n",
    "    # Synaptic models\n",
    "    \"Syn12\": \"\"\"\n",
    "        count : 1\n",
    "        X_condition : 1\n",
    "        dc/dt = -c/tau_c + J_C*count*Hz: 1 (clock-driven)\n",
    "        dX/dt = (alpha*int(X > theta_X)*int(X < X_max) - beta*int(X <= theta_X)*int(X > X_min))*(1 - X_condition) : 1 (clock-driven)\n",
    "        w = int(X >= 0.5) : 1\n",
    "        sum_w_post = w : 1 (summed)\n",
    "        \"\"\",\n",
    "    \"Syn22\": \"\"\"\n",
    "        w : 1\n",
    "        \"\"\",\n",
    "    # Synaptic events\n",
    "    \"Pre12\": \"\"\"\n",
    "        g_e_post += w_e*int(sum_w_post >= 1)/(sum_w_post + 1e-13)*X\n",
    "        X += a*int(v_pre > theta_v)*int(theta_lup < c)*int(c < theta_hup) - b*int(v_pre <= theta_v)*int(theta_ldown < c)*int(c < theta_hdown)\n",
    "        X = clip(X, X_min, X_max)\n",
    "        X_condition = int(v_pre > theta_v)*int(theta_lup < c)*int(c < theta_hup) + int(v_pre <= theta_v)*int(theta_ldown < c)*int(c < theta_hdown)\n",
    "        \"\"\",\n",
    "    \"Pre22\": \"\"\"\n",
    "        g_i_post += w_i*abs(i-j)\n",
    "        \"\"\",\n",
    "    \"Post12\": \"\"\"\n",
    "        count += 1\n",
    "        X_condition = 0\n",
    "        \"\"\",\n",
    "}\n",
    "\n",
    "connections = {\n",
    "    \"Syn12\": {\"mode\": \"balanced_random\"},\n",
    "    \"Syn22\": {\"mode\": \"different\"},\n",
    "}\n",
    "\n",
    "recordings = {\n",
    "    \"L1\": [\"v\"],\n",
    "    \"L2\": [\"v\"],\n",
    "    \"Syn12\": [\"c\", \"X\", \"w\"],\n",
    "}\n",
    "\n",
    "initial_values = {\n",
    "    \"L1\": {\"v\": \"V_res + rand()*(V_theta - V_res)\"},\n",
    "    \"L2\": {\n",
    "        \"v\": \"V_res + rand()*(V_theta - V_res)\",\n",
    "        \"v_th\": \"V_theta\",\n",
    "        \"g_e\": 0 * nS,\n",
    "        \"g_i\": 0 * nS,\n",
    "    },\n",
    "    \"Syn12\": {\"count\": 0, \"c\": 2, \"X\": \"rand()*X_max\", \"delay\": \"rand()*tau_r\"},\n",
    "    \"Syn22\": {\"w\": 1},\n",
    "}\n",
    "\n",
    "\n",
    "def generate_conns(N, M, mode=\"full\"):\n",
    "    \"\"\"Generate connection patterns for the Synapses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        N : int\n",
    "            Number of incoming synapses.\n",
    "        M : int\n",
    "            Number of outgoing synapses.\n",
    "        mode : {'different', 'full', 'random'}, default='full'\n",
    "            Connection mode.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        i, j, condition, p: (int, int, str, float)\n",
    "            Synaptic connection configs.\n",
    "\n",
    "    \"\"\"\n",
    "    i, j = None, None\n",
    "    condition = None\n",
    "    p = 1.0\n",
    "\n",
    "    match mode:\n",
    "        case \"different\":\n",
    "            condition = \"i != j\"\n",
    "        case \"full\":\n",
    "            i = np.repeat(np.arange(N), M)\n",
    "            j = np.tile(np.arange(M), N)\n",
    "        case \"gaussian\":\n",
    "            p = \"1.0 * exp(-((x_pre-x_post)**2 + (y_pre-y_post)**2)/(sqrt(2)*rf_size**2))\"\n",
    "        case \"random\":\n",
    "            p = \"rand()\"\n",
    "        case \"balanced_random\":\n",
    "            i = np.arange(N)\n",
    "            np.random.shuffle(i)\n",
    "            j = np.zeros(N, dtype=int)\n",
    "            j[0 : N // M * M] = np.repeat(np.arange(M), N // M)\n",
    "\n",
    "    return i, j, condition, p\n",
    "\n",
    "\n",
    "class TacNet(object):\n",
    "    def __init__(self, num_neurons: list, stimuli, receptive_field=\"random\") -> None:\n",
    "        \"\"\"Constructor of the Tactile Encoding Network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            num_neurons : list of int\n",
    "                List of numbers of neurons of each layer. 'L1' is the input layer.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            device.reinit()\n",
    "            device.activate()\n",
    "        except _:\n",
    "            pass\n",
    "\n",
    "        params[\"I\"] = stimuli\n",
    "        connections[\"Syn12\"][\"mode\"] = receptive_field\n",
    "\n",
    "        # Define NeuronGroups (layers)\n",
    "        neuron_groups = {}\n",
    "        for index, n_neuron in enumerate(num_neurons):\n",
    "            layer_name = \"L%d\" % (index + 1)\n",
    "            event_name = \"event%d\" % (index + 1)\n",
    "\n",
    "            if event_name in events:\n",
    "                event_label = events[event_name][0]\n",
    "                event_trigger = events[event_name][1]\n",
    "                event_operation = events[event_name][2]\n",
    "                event = {event_label: event_trigger}\n",
    "            else:\n",
    "                event = None\n",
    "            \n",
    "            # Check v_th for adaptive thresholding\n",
    "            threshold = \"V_theta\"\n",
    "            if \"threshold\" in event_name:\n",
    "                threshold = \"v_th\"\n",
    "                \n",
    "            neuron_groups[layer_name] = NeuronGroup(\n",
    "                n_neuron,\n",
    "                model=eqs[layer_name],\n",
    "                method=\"euler\",\n",
    "                threshold=\"v > %s\" % threshold,\n",
    "                reset=\"v = V_res\",\n",
    "                refractory=\"tau_r\",\n",
    "                events=event,\n",
    "                namespace=params,\n",
    "                name=layer_name,\n",
    "            )\n",
    "            if event is not None:\n",
    "                neuron_groups[layer_name].run_on_event(event_label, event_operation)\n",
    "\n",
    "        # Define Synapses\n",
    "        synapses = {}\n",
    "        for source in range(len(num_neurons)):\n",
    "            for target in range(len(num_neurons)):\n",
    "                link = \"%d%d\" % (source + 1, target + 1)\n",
    "                syn_name = \"Syn\" + link\n",
    "                pre_name = \"Pre\" + link\n",
    "                post_name = \"Post\" + link\n",
    "                if syn_name in eqs:\n",
    "                    if pre_name in eqs:\n",
    "                        on_pre = eqs[pre_name]\n",
    "                    else:\n",
    "                        on_pre = None\n",
    "                    if post_name in eqs:\n",
    "                        on_post = eqs[post_name]\n",
    "                    else:\n",
    "                        on_post = None\n",
    "                    synapses[syn_name] = Synapses(\n",
    "                        neuron_groups[\"L%d\" % (source + 1)],\n",
    "                        neuron_groups[\"L%d\" % (target + 1)],\n",
    "                        model=eqs[syn_name],\n",
    "                        on_pre=on_pre,\n",
    "                        on_post=on_post,\n",
    "                        namespace=params,\n",
    "                        method=\"euler\",\n",
    "                        name=syn_name,\n",
    "                    )\n",
    "\n",
    "        # Connect synapses\n",
    "        for synapse in synapses.values():\n",
    "            mode = connections[synapse.name][\"mode\"]\n",
    "            source, target, condition, p = generate_conns(\n",
    "                synapse.source.N, synapse.target.N, mode=mode\n",
    "            )\n",
    "            synapse.connect(i=source, j=target, condition=condition, p=p)\n",
    "\n",
    "        # Define Monitors\n",
    "        self.mons = dict()\n",
    "        for layer in neuron_groups.values():\n",
    "            mon_name = \"SpikeMonitor_\" + layer.name\n",
    "            self.mons[mon_name] = SpikeMonitor(layer, record=True, name=mon_name)\n",
    "        for k, v in recordings.items():\n",
    "            mon_name = \"StateMonitor_\" + k\n",
    "            if k in neuron_groups:\n",
    "                G = neuron_groups[k]\n",
    "                record = True\n",
    "            if k in synapses:\n",
    "                G = synapses[k]\n",
    "                record = np.arange(G.source.N * G.target.N)\n",
    "            if \"G\" in locals():\n",
    "                self.mons[mon_name] = StateMonitor(G, v, record=record, name=mon_name)\n",
    "\n",
    "        # Add all groups to the network\n",
    "        self.net = Network()\n",
    "        for layer in neuron_groups.values():\n",
    "            self.net.add(layer)\n",
    "        for synapse in synapses.values():\n",
    "            self.net.add(synapse)\n",
    "        for monitor in self.mons.values():\n",
    "            self.net.add(monitor)\n",
    "            \n",
    "        self.initiate(initial_values)\n",
    "\n",
    "    def initiate(self, initial_values: dict):\n",
    "        \"\"\"Set initial values for the simulator.\n",
    "\n",
    "        Parameters\n",
    "            initial_values (dict): _description_\n",
    "        \"\"\"\n",
    "        for k, iv_dict in initial_values.items():\n",
    "            for attr, iv in iv_dict.items():\n",
    "                setattr(self.net[k], attr, iv)\n",
    "\n",
    "    def run(self, duration, save_state=None):\n",
    "        \"\"\"Run the simulation for a duration and save the state(optional).\n",
    "\n",
    "        Parameters\n",
    "            duration (Quantity): Time to run the simulation.\n",
    "            save_state (str): Filepath to save the state. Defaults to None.\n",
    "\n",
    "        Returns\n",
    "            dict: A dictionary of Monitors.\n",
    "        \"\"\"\n",
    "        self.net.run(duration=duration)\n",
    "        return self.mons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brian2 Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 wngfra.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "class BarGenerator:\n",
    "    def __init__(self, shape):\n",
    "        self._shape = np.asarray(shape)\n",
    "\n",
    "    def __call__(self, shift=None, angle=0, dim=(1, 1)):\n",
    "        \"\"\"Generate a bar with given shape.\n",
    "\n",
    "        Args:\n",
    "            shift (tuple, optional): Shift of the bar centre. Defaults to image centre.\n",
    "            angle (float, optional): Angle of the bar. Defaults to 0.\n",
    "            dim (tuple, optional): Dimension of the bar. Defaults to (1, 1).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Bar with shape (width, shape[1]).\n",
    "        \"\"\"\n",
    "        # Compute the new side length for the padded image\n",
    "        L = linalg.norm(self.shape).astype(int)\n",
    "        if L % 2 == 0:\n",
    "            L += 1\n",
    "        padded = np.zeros((L, L))\n",
    "        if dim[0] > L or dim[1] > L:\n",
    "            raise ValueError(\"Bar dimension is larger than image size.\")\n",
    "        padded[\n",
    "            L // 2 - dim[0] // 2 : L // 2 - dim[0] // 2 + dim[0],\n",
    "            L // 2 - dim[1] // 2 : L // 2 - dim[1] // 2 + dim[1],\n",
    "        ] = 1\n",
    "        padded = ndimage.rotate(padded, angle)\n",
    "        if shift:\n",
    "            padded = ndimage.shift(padded, shift)\n",
    "        padbottom, padleft = (padded.shape - self.shape) // 2\n",
    "\n",
    "        cropped = padded[\n",
    "            padbottom : padbottom + self.shape[0], padleft : padleft + self.shape[1]\n",
    "        ]\n",
    "\n",
    "        cropped[cropped < 0.1] = 0\n",
    "        cropped /= cropped.max() if cropped.max() > 0 else 1\n",
    "\n",
    "        return cropped\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self._shape\n",
    "\n",
    "    @shape.setter\n",
    "    def shape(self, shape):\n",
    "        self._shape = shape\n",
    "\n",
    "    def generate_samples(\n",
    "        self, num_samples, dim, shift=None, start_angle=0, step=1, add_test=False\n",
    "    ):\n",
    "        bars = [self(shift, start_angle + i * step, dim) for i in range(num_samples)]\n",
    "        info = np.arange(start_angle, start_angle + num_samples * step, step)\n",
    "        bars = np.asarray(bars)\n",
    "        info = np.asarray(info)\n",
    "        if add_test:\n",
    "            rng = np.random.default_rng(seed=0)\n",
    "            arr = np.arange(num_samples, dtype=int)\n",
    "            np.random.shuffle(arr)\n",
    "            bars = np.concatenate((bars, bars[arr]))\n",
    "            info = np.concatenate((info, info[arr]))\n",
    "        return bars, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The indices to record from contain values outside of the range [0, 224] allowed for the group 'Syn12'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m I \u001b[39m=\u001b[39m TimedArray(inputs \u001b[39m*\u001b[39m \u001b[39m200\u001b[39m \u001b[39m*\u001b[39m pA, dt\u001b[39m=\u001b[39mdt)\n\u001b[1;32m     46\u001b[0m num_neurons \u001b[39m=\u001b[39m [height \u001b[39m*\u001b[39m width, \u001b[39m18\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m model \u001b[39m=\u001b[39m TacNet(num_neurons, I, receptive_field\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbalanced_random\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     48\u001b[0m total_time \u001b[39m=\u001b[39m I\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m dt\n\u001b[1;32m     49\u001b[0m mons \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mrun(duration)\n",
      "Cell \u001b[0;32mIn[36], line 250\u001b[0m, in \u001b[0;36mTacNet.__init__\u001b[0;34m(self, num_neurons, stimuli, receptive_field)\u001b[0m\n\u001b[1;32m    248\u001b[0m         record \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(G\u001b[39m.\u001b[39msource\u001b[39m.\u001b[39mN \u001b[39m*\u001b[39m G\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mN)\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mG\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mlocals\u001b[39m():\n\u001b[0;32m--> 250\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmons[mon_name] \u001b[39m=\u001b[39m StateMonitor(G, v, record\u001b[39m=\u001b[39;49mrecord, name\u001b[39m=\u001b[39;49mmon_name)\n\u001b[1;32m    252\u001b[0m \u001b[39m# Add all groups to the network\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet \u001b[39m=\u001b[39m Network()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/brian2/monitors/statemonitor.py:218\u001b[0m, in \u001b[0;36mStateMonitor.__init__\u001b[0;34m(self, source, variables, record, dt, clock, when, order, name, codeobj_class)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(record) \u001b[39mand\u001b[39;00m (np\u001b[39m.\u001b[39mmax(record) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(source) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39mmin(record) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    215\u001b[0m         \u001b[39m# Check whether the values in record make sense\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         error_message \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe indices to record from contain values outside of the range \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[0, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(source)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] allowed for the group \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 218\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(error_message)\n\u001b[1;32m    219\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     logger\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mCannot check whether the indices to record from are valid. This can happen \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39min standalone mode when recording from synapses that have been created with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39ma connection pattern. You can avoid this situation by using synaptic indices \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39min the connect call.\u001b[39m\u001b[39m\"\u001b[39m, name_suffix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcannot_check_statemonitor_indices\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: The indices to record from contain values outside of the range [0, 224] allowed for the group 'Syn12'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from brian2 import *\n",
    "from brian2tools import brian_plot, plot_state\n",
    "\n",
    "matplotlib.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "# prefs.devices.cpp_standalone.openmp_threads = 3\n",
    "set_device(\"cpp_standalone\")\n",
    "\n",
    "stim_shape = (15, 15)\n",
    "stim_size = np.prod(stim_shape)\n",
    "num_samples = 18\n",
    "\n",
    "# Prepare dataset\n",
    "bg = BarGenerator(stim_shape)\n",
    "X_in, y_in = bg.generate_samples(\n",
    "    num_samples=num_samples,\n",
    "    dim=(3, 15),\n",
    "    shift=(0, 0),\n",
    "    start_angle=0,\n",
    "    step=180 / num_samples,\n",
    "    add_test=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Augment data\n",
    "n = 300  # repetition per stimulus\n",
    "samples, orientations = np.repeat(X_in, n, axis=0), np.repeat(\n",
    "    y_in, n, axis=0\n",
    ")\n",
    "\n",
    "# Prepare simulation\n",
    "# Convert values to spikes\n",
    "dt = 1 * ms\n",
    "duration = len(samples) * ms\n",
    "length, height, width = samples.shape\n",
    "inputs = samples.reshape(length, -1)\n",
    "inputs[inputs > inputs.mean()] = 1\n",
    "inputs[inputs < 1] = 0\n",
    "\n",
    "I = TimedArray(inputs * 200 * pA, dt=dt)\n",
    "num_neurons = [height * width, 18]\n",
    "model = TacNet(num_neurons, I, receptive_field=\"balanced_random\")\n",
    "total_time = I.values.shape[0] * dt\n",
    "mons = model.run(duration)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(7, 1, figsize=(12, 20))\n",
    "for i in range(2):\n",
    "    axs[i].set_title(\"Spike L\" + str(i + 1))\n",
    "    brian_plot(mons[\"SpikeMonitor_L\" + str(i + 1)], axes=axs[i])\n",
    "\n",
    "axs[3].plot(orientations[: int(duration / dt)])\n",
    "axs[3].set_title(\"Rotation Angles\")\n",
    "axs[3].set_xlabel(\"time (ms)\")\n",
    "axs[3].set_ylabel(r\"deg ($^{\\circ}$)\")\n",
    "axs[4].set_title(\"L2 Membrane Potential\")\n",
    "plot_state(mons[\"StateMonitor_L2\"].t, mons[\"StateMonitor_L2\"].v.T, axes=axs[4])\n",
    "axs[5].set_title(\"Syn12 c (Calcium Variable)\")\n",
    "plot_state(mons[\"StateMonitor_Syn12\"].t, mons[\"StateMonitor_Syn12\"].X.T, axes=axs[5])\n",
    "axs[6].set_title(\"Syn12 Connectivity\")\n",
    "brian_plot(model.net[\"Syn12\"], axes=axs[6])\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "ax.imshow(mons[\"StateMonitor_Syn12\"].w_[:, 0:-1:200].reshape(num_neurons[1]*num_neurons[2], -1))\n",
    "ax.set_title(\"Syn12 Weights\")\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "ax.set_ylabel(\"Synapse Index\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reference\n",
    "[1] A. Parvizi-Fard, M. Amiri, D. Kumar, M. M. Iskarous, and N. V. Thakor, “A functional spiking neuronal network for tactile sensing pathway to process edge orientation,” Sci Rep, vol. 11, no. 1, p. 1320, Dec. 2021, doi: 10.1038/s41598-020-80132-4.\n",
    "\n",
    "[2] X. She, S. Dash, D. Kim, and S. Mukhopadhyay, “A Heterogeneous Spiking Neural Network for Unsupervised Learning of Spatiotemporal Patterns,” Front. Neurosci., vol. 14, p. 615756, Jan. 2021, doi: 10.3389/fnins.2020.615756.\n",
    "\n",
    "[3] J. A. Pruszynski and R. S. Johansson, “Edge-orientation processing in first-order tactile neurons,” Nat Neurosci, vol. 17, no. 10, pp. 1404–1409, Oct. 2014, doi: 10.1038/nn.3804.\n",
    "\n",
    "[4] J. A. Pruszynski, J. R. Flanagan, and R. S. Johansson, “Fast and accurate edge orientation processing during object manipulation,” eLife, vol. 7, p. e31200, Apr. 2018, doi: 10.7554/eLife.31200.\n",
    "\n",
    "[5] J. Platkiewicz, “Haptic Edge Detection Through Shear,” Scientific Reports, p. 10.\n",
    "\n",
    "[6] J. M. Brader, W. Senn, and S. Fusi, “Learning Real-World Stimuli in a Neural Network with Spike-Driven Synaptic Dynamics,” Neural Computation, vol. 19, no. 11, pp. 2881–2912, Nov. 2007, doi: 10.1162/neco.2007.19.11.2881.\n",
    "\n",
    "[7] T. Barbier, C. Teuliere, and J. Triesch, “Spike timing-based unsupervised learning of orientation, disparity, and motion representations in a spiking neural network,” in 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Nashville, TN, USA, Jun. 2021, pp. 1377–1386. doi: 10.1109/CVPRW53098.2021.00152."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "90%",
   "scroll": true,
   "theme": "sky",
   "transition": "zoom"
  },
  "vscode": {
   "interpreter": {
    "hash": "f810fd30917845ff934f7c6e23efdc5b50e9400772765ac0b00dcbae448bd04a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
