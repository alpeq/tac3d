{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# MuJoCo Robotic Simulation Generating Synthetic Data\n",
    "* Franka-Emika Panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MUJOCO_GL = egl\n",
    "%matplotlib widget\n",
    "import os\n",
    "import pickle\n",
    "from multiprocessing import Lock, Pool\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Access to enums and MuJoCo library functions.\n",
    "from dm_control import mujoco\n",
    "from dm_control.mujoco.wrapper.mjbindings import mjlib\n",
    "from dm_control.utils import inverse_kinematics as ik\n",
    "from IPython.display import HTML, clear_output, display\n",
    "from PIL import Image\n",
    "from scipy.special import gamma\n",
    "\n",
    "# Rendering parameters\n",
    "dpi = 100\n",
    "framerate = 30  # (Hz)\n",
    "width, height = 1280, 720\n",
    "\n",
    "# IK solver parameters\n",
    "_MAX_STEPS = 100\n",
    "_TOL = 1e-12\n",
    "\n",
    "# Scene XML\n",
    "robot_xml = \"../models/panda_nohand.xml\"\n",
    "scene_xml = \"../models/scene.xml\"\n",
    "site_name = \"attachment_site\"\n",
    "reach_sites = [\"sharp_site\", \"round_site\", \"wedge_site\"]\n",
    "actuator_id = {\"sharp_site\": 1, \"round_site\": 2, \"wedge_site\": 3}\n",
    "joint_names = [\"joint{}\".format(i + 1) for i in range(7)]\n",
    "\n",
    "# Multiprocessing lock\n",
    "threaded = False\n",
    "if threaded:\n",
    "    lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## [Optional]Update The Scene XML File\n",
    "* [Mujoco XML Reference](https://mujoco.readthedocs.io/en/latest/XMLreference.html?highlight=site#body-site)\n",
    "* [The ElementTree XML API](https://docs.python.org/3/library/xml.etree.elementtree.html)\n",
    "\n",
    "### Tactile Sensor\n",
    "\n",
    "1. Sensor Pad \n",
    "* for visual only\n",
    "\n",
    "2. Collision Balls (mono-layer)\n",
    "* _M: (x-count, y-count)\n",
    "* geom_type: [sphere, capsule, ellipsoid, cylinder, box], “sphere”\n",
    "* dx: the distance between each site\n",
    "* offset: uniform distance to shift all sites\n",
    "\n",
    "3. Slide Joints\n",
    "* connect the balls to the pad\n",
    "* joint positions serve as sensory values\n",
    "* small time constant\n",
    "\n",
    "4. Tendons to Connect Balls\n",
    "* planar spring connection\n",
    "* creates contact-force distribution\n",
    "\n",
    "### Key Frames\n",
    "* Initial poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robotic Simulation for Tactile Encoding Test\n",
    "\n",
    "* Synthetic data generation\n",
    "    - Check [models](../models/platform.xml) for edge types\n",
    "* Save sensor data and simulation\n",
    "    - [Sensordata](touch3edge.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(\n",
    "    scene_xml, site_name, target_name, joint_names, duration=2.0, rendered=True\n",
    "):\n",
    "    physics = mujoco.Physics.from_xml_path(scene_xml)\n",
    "    physics.reset(0)\n",
    "\n",
    "    omega = 4 * np.pi / duration * np.array([1, 1, 1])\n",
    "    ctrl = np.empty(10)\n",
    "    video = []\n",
    "    stream = []\n",
    "    orientations = []\n",
    "    control_site = physics.data.site(name=site_name)\n",
    "    target_site = physics.data.site(name=target_name)\n",
    "    target_quat = R.from_matrix(control_site.xmat.reshape((3,3))).as_quat()\n",
    "    target_xpos = target_site.xpos.copy()\n",
    "    target_xpos[2] -= 1e-3\n",
    "    smooth_factor = 0.5\n",
    "\n",
    "    # Simulate, saving video frames\n",
    "    while physics.data.time <= duration:\n",
    "        move_vec = (\n",
    "            (target_xpos - control_site.xpos)\n",
    "            * min(smooth_factor, physics.data.time)\n",
    "            / smooth_factor\n",
    "        )\n",
    "        # Compute the inverse kinematics\n",
    "        if np.linalg.norm(control_site.xpos - target_xpos) > _TOL:\n",
    "            result = ik.qpos_from_site_pose(\n",
    "                physics,\n",
    "                site_name,\n",
    "                target_pos=control_site.xpos + move_vec,\n",
    "                target_quat=target_quat,\n",
    "                joint_names=joint_names,\n",
    "                tol=_TOL,\n",
    "                max_steps=_MAX_STEPS,\n",
    "                inplace=False,\n",
    "            )\n",
    "            ctrl[:7] = result.qpos[:7]\n",
    "        ctrl[-3:] = omega * physics.data.time\n",
    "        physics.set_control(ctrl)\n",
    "        physics.step()\n",
    "\n",
    "        # Save sensordata when there is contact\n",
    "        if len(physics.data.contact) > 0:\n",
    "            sensordata = physics.data.sensordata.copy()\n",
    "            M = np.sqrt(sensordata.shape[0]).astype(int)\n",
    "            data = sensordata.reshape(M, M)\n",
    "            stream.append(data)\n",
    "            oris = physics.named.data.qpos[\n",
    "                \"rotator_joint%d\" % actuator_id[target_name]\n",
    "            ].copy()\n",
    "            orientations.append(oris)\n",
    "\n",
    "        # Save video frames\n",
    "        clear_output(wait=True)\n",
    "        print(\n",
    "            \"PID {} simulating {}. Progress: {:.1f}%\".format(\n",
    "                os.getpid(), target_name, physics.data.time / duration * 100\n",
    "            )\n",
    "        )\n",
    "        if rendered and len(video) < physics.data.time * framerate:\n",
    "            if threaded:\n",
    "                lock.acquire()\n",
    "            pixels = physics.render(camera_id=\"prospective\", width=width, height=height)\n",
    "            if threaded:\n",
    "                lock.release()\n",
    "            video.append(pixels.copy())\n",
    "\n",
    "    return target_name, video, stream, orientations\n",
    "\n",
    "\n",
    "ds = dict()\n",
    "\n",
    "for rs in reach_sites:\n",
    "    label, video, stream, orientations = gen_dataset(\n",
    "        scene_xml, site_name, rs, joint_names, duration=7.0, rendered=True\n",
    "    )\n",
    "    ds[label] = {\"sensordata\": stream, \"orientations\": orientations}\n",
    "    media.write_video(\"../data/\" + label + \".mp4\", video, fps=30)\n",
    "\n",
    "with open(\"../data/touch.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ds, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(url=\"../docs/round_site.mp4\", width=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Visualize Tactile Signals\n",
    "* $15 \\times 15$ taxels simulated by damped spring-linked particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from TouchDataset import TouchDataset\n",
    "\n",
    "dataset = TouchDataset(\"../data/touch.pkl\", noise_scale=5e-2, flatten=False)\n",
    "image = Image.open(\"../docs/soft_contact.png\")\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax0 = plt.subplot(121)\n",
    "ax0.imshow(image)\n",
    "ax1 = plt.subplot(133)\n",
    "ax1.imshow(dataset[1000][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Unsupervised Edge Orientation Classifier\n",
    "1. 3-Layer Layer Spiking Neural Network\n",
    "2. Binary input layer\n",
    "3. Random receptive field - 25 neurons\n",
    "4. Edge Orientation Output - 36 neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network structure and hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from brian2 import *\n",
    "\n",
    "events = {\"event3\": [\"increase_threshold\", \"v > v_th\", \"v_th += delta_theta*rand()\"]}\n",
    "\n",
    "params = {\n",
    "    # Model constants\n",
    "    \"C_mem\": 200 * pF,  # Membrane capacitance\n",
    "    \"delta_theta\": 3 * mV,  # Adaptive threshold incremental scale\n",
    "    \"g_l\": 10 * nS,  # Leak conductance\n",
    "    \"J_C\": 1,  # Scale of the calcium variable\n",
    "    \"tau_c\": 60 * ms,  # Calcium variable time constant\n",
    "    \"tau_e\": 10 * ms,  # Excitatory synaptic time constant\n",
    "    \"tau_i\": 10 * ms,  # Inhibitory synaptic time constant\n",
    "    \"tau_r\": 5 * ms,  # Refractory period\n",
    "    \"tau_theta\": 5 * ms,  # Adaptive threshold time constant\n",
    "    \"V_ir\": -80 * mV,  # Inhibitory reverse potential\n",
    "    \"V_res\": -65 * mV,  # Resting potential\n",
    "    \"V_theta\": -55 * mV,  # Spiking threshold\n",
    "    \"w_e\": 20 * nS,  # Excitatory conductance increment\n",
    "    \"w_i\": 30 * nS,  # Inhibitory conductance increment\n",
    "    \"X_max\": 1,  # Synaptic variable maximum\n",
    "    \"X_min\": 0,  # Synaptic variable minimum\n",
    "    # Simulation parameters\n",
    "    \"defaultclock.dt\": 0.1 * ms,  # Time step\n",
    "}\n",
    "\n",
    "# Thresholds and plasticity parameters\n",
    "params[\"a\"] = 0.1 * params[\"X_max\"]\n",
    "params[\"b\"] = 0.1 * params[\"X_max\"]\n",
    "params[\"alpha\"] = 3.5 * params[\"X_max\"] * Hz\n",
    "params[\"beta\"] = 3.5 * params[\"X_max\"] * Hz\n",
    "params[\"theta_hup\"] = 12 * params[\"J_C\"]\n",
    "params[\"theta_lup\"] = 3 * params[\"J_C\"]\n",
    "params[\"theta_hdown\"] = 4 * params[\"J_C\"]\n",
    "params[\"theta_ldown\"] = 3 * params[\"J_C\"]\n",
    "params[\"theta_v\"] = 0.8 * params[\"V_theta\"]\n",
    "params[\"theta_X\"] = 0.5 * params[\"X_max\"]\n",
    "params[\"learning_switch\"] = 1\n",
    "\n",
    "eqs = {\n",
    "    # Neuronal models\n",
    "    \"L1\": \"\"\"\n",
    "        dv/dt = (g_l*(V_res - v) + I(t,i))/C_mem : volt (unless refractory)\n",
    "        x : 1\n",
    "        y : 1\n",
    "        \"\"\",\n",
    "    \"L2\": \"\"\"\n",
    "        dv/dt = (g_l*(V_res - v) - g_e*v)/C_mem : volt (unless refractory)\n",
    "        dg_e/dt = -g_e/tau_e : siemens\n",
    "        sum_w : 1\n",
    "        x : 1\n",
    "        y : 1\n",
    "        \"\"\",\n",
    "    \"L3\": \"\"\"\n",
    "        dv/dt = (g_l*(V_res - v) - g_e*v + learning_switch*tg_i*(V_ir - v))/C_mem : volt (unless refractory)\n",
    "        dg_e/dt = -g_e/tau_e : siemens\n",
    "        dg_i/dt = -g_i/tau_i : siemens\n",
    "        dv_th/dt = (V_theta - v_th)/tau_theta : volt\n",
    "        sum_w : 1\n",
    "        \"\"\",\n",
    "    \"L4\": \"\"\"\n",
    "        dv/dt = (g_l*(V_res - v) - g_e*v + g_i*(V_ir - v))/C_mem : volt (unless refractory)\n",
    "        dg_e/dt = -g_e/tau_e : siemens\n",
    "        dg_i/dt = -g_i/tau_i : siemens\n",
    "        sum_w : 1\n",
    "        \"\"\",\n",
    "    # Synaptic models\n",
    "    \"Syn12\": \"\"\"\n",
    "        w : 1\n",
    "        sum_w_post = w : 1 (summed)\n",
    "        \"\"\",\n",
    "    \"Syn23\": \"\"\"\n",
    "        count : 1\n",
    "        X_condition : 1\n",
    "        dc/dt = -c/tau_c + J_C*count*Hz: 1 (clock-driven)\n",
    "        dX/dt = (alpha*int(X > theta_X)*int(X < X_max) - beta*int(X <= theta_X)*int(X > X_min))*(1 - X_condition) : 1 (clock-driven)\n",
    "        w = int(X >= 0.5) : 1\n",
    "        sum_w_post = w : 1 (summed)\n",
    "        \"\"\",\n",
    "    \"Syn33\": \"\"\"\n",
    "        w : 1\n",
    "        \"\"\",\n",
    "    \"Syn34\": \"\"\"\n",
    "        w : 1\n",
    "        \"\"\",\n",
    "    # Synaptic events\n",
    "    \"Pre12\": \"\"\"\n",
    "        g_e_post += w_e/sum_w_post\n",
    "        \"\"\",\n",
    "    \"Pre23\": \"\"\"\n",
    "        g_e_post += w_e*int(sum_w_post >= 1)/(sum_w_post + 1e-13)*X\n",
    "        X += a*int(v_pre > theta_v)*int(theta_lup < c)*int(c < theta_hup) - b*int(v_pre <= theta_v)*int(theta_ldown < c)*int(c < theta_hdown)\n",
    "        X = clip(X, X_min, X_max)\n",
    "        X_condition = int(v_pre > theta_v)*int(theta_lup < c)*int(c < theta_hup) + int(v_pre <= theta_v)*int(theta_ldown < c)*int(c < theta_hdown)\n",
    "        \"\"\",\n",
    "    \"Pre33\": \"\"\"\n",
    "        g_i_post += w_i*abs(i-j)\n",
    "        \"\"\",\n",
    "    \"Post23\": \"\"\"\n",
    "        count += 1\n",
    "        X_condition = 0\n",
    "        \"\"\",\n",
    "    \"Pre34\": \"\"\"\n",
    "        g_i_post += w_i\n",
    "        \"\"\",\n",
    "}\n",
    "\n",
    "connections = {\n",
    "    \"Syn12\": {\"mode\": \"balanced_random\"},\n",
    "    \"Syn23\": {\"mode\": \"full\"},\n",
    "    \"Syn33\": {\"mode\": \"different\"},\n",
    "    \"Syn34\": {\"mode\": \"different\"},\n",
    "}\n",
    "\n",
    "recordings = {\n",
    "    \"L1\": [\"v\"],\n",
    "    \"L2\": [\"v\"],\n",
    "    \"L3\": [\"v\"],\n",
    "    \"L4\": [\"v\"],\n",
    "    \"Syn23\": [\"X\", \"w\"],\n",
    "}\n",
    "\n",
    "initial_values = {\n",
    "    \"L1\": {\"v\": \"V_res + rand()*(V_theta - V_res)\"},\n",
    "    \"L2\": {\"v\": \"V_res + rand()*(V_theta - V_res)\"},\n",
    "    \"L3\": {\n",
    "        \"v\": \"V_res + rand()*(V_theta - V_res)\",\n",
    "        \"v_th\": \"V_theta\",\n",
    "        \"g_e\": 0 * nS,\n",
    "        \"g_i\": 0 * nS,\n",
    "    },\n",
    "    \"L4\": {\n",
    "        \"v\": \"V_res + rand()*(V_theta - V_res)\",\n",
    "        \"g_e\": 0 * nS,\n",
    "        \"g_i\": 0 * nS,\n",
    "    },\n",
    "    \"Syn12\": {\"w\": 1},\n",
    "    \"Syn23\": {\"count\": 0, \"c\": 2, \"X\": \"rand()*X_max\", \"delay\": \"rand()*tau_r\"},\n",
    "    \"Syn33\": {\"w\": 1},\n",
    "    \"Syn34\": {\"w\": 1},\n",
    "}\n",
    "\n",
    "\n",
    "def generate_conns(N, M, mode=\"full\"):\n",
    "    \"\"\"Generate connection patterns for the Synapses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        N : int\n",
    "            Number of incoming synapses.\n",
    "        M : int\n",
    "            Number of outgoing synapses.\n",
    "        mode : {'different', 'full', 'random'}, default='full'\n",
    "            Connection mode.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        i, j, condition, p: (int, int, str, float)\n",
    "            Synaptic connection configs.\n",
    "\n",
    "    \"\"\"\n",
    "    i, j = None, None\n",
    "    condition = None\n",
    "    p = 1.0\n",
    "\n",
    "    match mode:\n",
    "        case \"different\":\n",
    "            condition = \"i != j\"\n",
    "        case \"full\":\n",
    "            i = np.repeat(np.arange(N), M)\n",
    "            j = np.tile(np.arange(M), N)\n",
    "        case \"gaussian\":\n",
    "            p = \"1.0 * exp(-((x_pre-x_post)**2 + (y_pre-y_post)**2)/(sqrt(2)*rf_size**2))\"\n",
    "        case \"random\":\n",
    "            p = \"rand()\"\n",
    "        case \"balanced_random\":\n",
    "            i = np.arange(N)\n",
    "            np.random.shuffle(i)\n",
    "            j = np.zeros(N, dtype=int)\n",
    "            j[0 : N // M * M] = np.repeat(np.arange(M), N // M)\n",
    "\n",
    "    return i, j, condition, p\n",
    "\n",
    "\n",
    "class TacNet(object):\n",
    "    def __init__(self, num_neurons: list, stimuli, receptive_field=\"random\") -> None:\n",
    "        \"\"\"Constructor of the Tactile Encoding Network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            num_neurons : list of int\n",
    "                List of numbers of neurons of each layer. 'L1' is the input layer.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            device.reinit()\n",
    "            device.activate()\n",
    "        except _:\n",
    "            pass\n",
    "\n",
    "        params[\"I\"] = stimuli\n",
    "        connections[\"Syn12\"][\"mode\"] = receptive_field\n",
    "\n",
    "        # Define NeuronGroups (layers)\n",
    "        neuron_groups = {}\n",
    "        for index, n_neuron in enumerate(num_neurons):\n",
    "            layer_name = \"L%d\" % (index + 1)\n",
    "            event_name = \"event%d\" % (index + 1)\n",
    "\n",
    "            if event_name in events:\n",
    "                event_label = events[event_name][0]\n",
    "                event_trigger = events[event_name][1]\n",
    "                event_operation = events[event_name][2]\n",
    "                event = {event_label: event_trigger}\n",
    "            else:\n",
    "                event = None\n",
    "            \n",
    "            # Check v_th for adaptive thresholding\n",
    "            if \n",
    "                \n",
    "            neuron_groups[layer_name] = NeuronGroup(\n",
    "                n_neuron,\n",
    "                model=eqs[layer_name],\n",
    "                method=\"euler\",\n",
    "                threshold=\"v > V_theta\",\n",
    "                reset=\"v = V_res\",\n",
    "                refractory=\"tau_r\",\n",
    "                events=event,\n",
    "                namespace=params,\n",
    "                name=layer_name,\n",
    "            )\n",
    "            if event is not None:\n",
    "                neuron_groups[layer_name].run_on_event(event_label, event_operation)\n",
    "\n",
    "        # Assign coordinates to L1 neurons\n",
    "        l1_size = sqrt(len(neuron_groups[\"L1\"]))\n",
    "        l2_size = sqrt(len(neuron_groups[\"L2\"]))\n",
    "        rf_size = l1_size / l2_size\n",
    "\n",
    "        neuron_groups[\"L1\"].x = \"i // l1_size\"\n",
    "        neuron_groups[\"L1\"].y = \"i % l1_size\"\n",
    "        neuron_groups[\"L2\"].x = \"rf_size // 2 + rf_size * (i // l2_size)\"\n",
    "        neuron_groups[\"L2\"].y = \"rf_size // 2 + rf_size * (i % l2_size)\"\n",
    "\n",
    "        # Define Synapses\n",
    "        synapses = {}\n",
    "        for source in range(len(num_neurons)):\n",
    "            for target in range(len(num_neurons)):\n",
    "                link = \"%d%d\" % (source + 1, target + 1)\n",
    "                syn_name = \"Syn\" + link\n",
    "                pre_name = \"Pre\" + link\n",
    "                post_name = \"Post\" + link\n",
    "                if syn_name in eqs:\n",
    "                    if pre_name in eqs:\n",
    "                        on_pre = eqs[pre_name]\n",
    "                    else:\n",
    "                        on_pre = None\n",
    "                    if post_name in eqs:\n",
    "                        on_post = eqs[post_name]\n",
    "                    else:\n",
    "                        on_post = None\n",
    "                    synapses[syn_name] = Synapses(\n",
    "                        neuron_groups[\"L%d\" % (source + 1)],\n",
    "                        neuron_groups[\"L%d\" % (target + 1)],\n",
    "                        model=eqs[syn_name],\n",
    "                        on_pre=on_pre,\n",
    "                        on_post=on_post,\n",
    "                        namespace=params,\n",
    "                        method=\"euler\",\n",
    "                        name=syn_name,\n",
    "                    )\n",
    "\n",
    "        # Connect synapses\n",
    "        for synapse in synapses.values():\n",
    "            mode = connections[synapse.name][\"mode\"]\n",
    "            source, target, condition, p = generate_conns(\n",
    "                synapse.source.N, synapse.target.N, mode=mode\n",
    "            )\n",
    "            synapse.connect(i=source, j=target, condition=condition, p=p)\n",
    "\n",
    "        # Define Monitors\n",
    "        self.mons = dict()\n",
    "        for layer in neuron_groups.values():\n",
    "            mon_name = \"SpikeMonitor_\" + layer.name\n",
    "            self.mons[mon_name] = SpikeMonitor(layer, record=True, name=mon_name)\n",
    "        for k, v in recordings.items():\n",
    "            mon_name = \"StateMonitor_\" + k\n",
    "            if k in neuron_groups:\n",
    "                G = neuron_groups[k]\n",
    "                record = True\n",
    "            if k in synapses:\n",
    "                G = synapses[k]\n",
    "                record = np.arange(G.source.N * G.target.N)\n",
    "            if \"G\" in locals():\n",
    "                self.mons[mon_name] = StateMonitor(G, v, record=record, name=mon_name)\n",
    "\n",
    "        # Add all groups to the network\n",
    "        self.net = Network()\n",
    "        for layer in neuron_groups.values():\n",
    "            self.net.add(layer)\n",
    "        for synapse in synapses.values():\n",
    "            self.net.add(synapse)\n",
    "        for monitor in self.mons.values():\n",
    "            self.net.add(monitor)\n",
    "\n",
    "        self.initiate(initial_values)\n",
    "\n",
    "    def initiate(self, initial_values: dict):\n",
    "        \"\"\"Set initial values for the simulator.\n",
    "\n",
    "        Parameters\n",
    "            initial_values (dict): _description_\n",
    "        \"\"\"\n",
    "        for k, iv_dict in initial_values.items():\n",
    "            for attr, iv in iv_dict.items():\n",
    "                setattr(self.net[k], attr, iv)\n",
    "\n",
    "    def run(self, duration, save_state=None):\n",
    "        \"\"\"Run the simulation for a duration and save the state(optional).\n",
    "\n",
    "        Parameters\n",
    "            duration (Quantity): Time to run the simulation.\n",
    "            save_state (str): Filepath to save the state. Defaults to None.\n",
    "\n",
    "        Returns\n",
    "            dict: A dictionary of Monitors.\n",
    "        \"\"\"\n",
    "        self.net.run(duration=duration)\n",
    "        return self.mons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brian2 Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from brian2 import *\n",
    "from brian2tools import brian_plot, plot_state\n",
    "from TouchDataset import TouchDataset\n",
    "\n",
    "matplotlib.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "# prefs.devices.cpp_standalone.openmp_threads = 3\n",
    "set_device(\"cpp_standalone\")\n",
    "\n",
    "\n",
    "def wrap2deg(rad):\n",
    "    theta = np.array(rad)\n",
    "    theta = theta.reshape(-1)\n",
    "    n = np.floor(theta / np.pi)\n",
    "    return (theta - n * np.pi) / np.pi * 180\n",
    "\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = TouchDataset(filepath=\"../data/touch.pkl\", noise_scale=0.01, scope=(0.0, 1.0))\n",
    "subset = dataset.subset(tags=[\"round_site\"])\n",
    "X_train, y_train, X_test, y_test = dataset.split_set(ratio=0.5)\n",
    "\n",
    "\n",
    "# Augment data\n",
    "n = 200  # repetition per stimulus\n",
    "samples, orientations = np.repeat(X_train, n, axis=0), np.repeat(\n",
    "    y_train, n, axis=0\n",
    ")\n",
    "\n",
    "# Prepare simulation\n",
    "# Convert values to spikes\n",
    "dt = 1 * ms\n",
    "duration = len(samples) * ms\n",
    "length, height, width = samples.shape\n",
    "inputs = samples.reshape(length, -1)\n",
    "inputs[inputs > inputs.mean()] = 1\n",
    "inputs[inputs < 1] = 0\n",
    "\n",
    "I = TimedArray(inputs * 200 * pA, dt=dt)\n",
    "num_neurons = [height * width, 20, 36]\n",
    "model = TacNet(num_neurons, I, receptive_field=\"gaussian\")\n",
    "total_time = I.values.shape[0] * dt\n",
    "mons = model.run(duration)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(7, 1, figsize=(12, 20))\n",
    "for i in range(3):\n",
    "    axs[i].set_title(\"Spike L\" + str(i + 1))\n",
    "    brian_plot(mons[\"SpikeMonitor_L\" + str(i + 1)], axes=axs[i])\n",
    "\n",
    "axs[3].plot(wrap2deg(orientations[: int(duration / dt)]))\n",
    "axs[3].set_title(\"Rotation Angles\")\n",
    "axs[3].set_xlabel(\"time (ms)\")\n",
    "axs[3].set_ylabel(r\"deg ($^{\\circ}$)\")\n",
    "axs[4].set_title(\"L3 Membrane Potential\")\n",
    "plot_state(mons[\"StateMonitor_L3\"].t, mons[\"StateMonitor_L3\"].v.T, axes=axs[4])\n",
    "axs[5].set_title(\"Syn23 X (Calcium Variable)\")\n",
    "plot_state(mons[\"StateMonitor_Syn23\"].t, mons[\"StateMonitor_Syn23\"].X.T, axes=axs[5])\n",
    "axs[6].set_title(\"Syn12 Connectivity\")\n",
    "brian_plot(model.net[\"Syn12\"], axes=axs[6])\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 10))\n",
    "axes[0].imshow(\n",
    "    mons[\"StateMonitor_Syn23\"].w_[:, 0].reshape((num_neurons[1], num_neurons[2]))\n",
    ")\n",
    "axes[0].set_title(\"Initial Weight\")\n",
    "axes[1].imshow(\n",
    "    mons[\"StateMonitor_Syn23\"].w_[:, -1].reshape((num_neurons[1], num_neurons[2]))\n",
    ")\n",
    "axes[1].set_title(\"Final Weight\")\n",
    "for i in range(2):\n",
    "    axes[i].set_xlabel(\"target neuron index\")\n",
    "    axes[i].set_ylabel(\"source neuron index\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[1] A. Parvizi-Fard, M. Amiri, D. Kumar, M. M. Iskarous, and N. V. Thakor, “A functional spiking neuronal network for tactile sensing pathway to process edge orientation,” Sci Rep, vol. 11, no. 1, p. 1320, Dec. 2021, doi: 10.1038/s41598-020-80132-4.\n",
    "\n",
    "[2] X. She, S. Dash, D. Kim, and S. Mukhopadhyay, “A Heterogeneous Spiking Neural Network for Unsupervised Learning of Spatiotemporal Patterns,” Front. Neurosci., vol. 14, p. 615756, Jan. 2021, doi: 10.3389/fnins.2020.615756.\n",
    "\n",
    "[3] J. A. Pruszynski and R. S. Johansson, “Edge-orientation processing in first-order tactile neurons,” Nat Neurosci, vol. 17, no. 10, pp. 1404–1409, Oct. 2014, doi: 10.1038/nn.3804.\n",
    "\n",
    "[4] J. A. Pruszynski, J. R. Flanagan, and R. S. Johansson, “Fast and accurate edge orientation processing during object manipulation,” eLife, vol. 7, p. e31200, Apr. 2018, doi: 10.7554/eLife.31200.\n",
    "\n",
    "[5] J. Platkiewicz, “Haptic Edge Detection Through Shear,” Scientific Reports, p. 10.\n",
    "\n",
    "[6] J. M. Brader, W. Senn, and S. Fusi, “Learning Real-World Stimuli in a Neural Network with Spike-Driven Synaptic Dynamics,” Neural Computation, vol. 19, no. 11, pp. 2881–2912, Nov. 2007, doi: 10.1162/neco.2007.19.11.2881.\n",
    "\n",
    "[7] T. Barbier, C. Teuliere, and J. Triesch, “Spike timing-based unsupervised learning of orientation, disparity, and motion representations in a spiking neural network,” in 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Nashville, TN, USA, Jun. 2021, pp. 1377–1386. doi: 10.1109/CVPRW53098.2021.00152."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "90%",
   "scroll": true,
   "theme": "sky",
   "transition": "zoom"
  },
  "vscode": {
   "interpreter": {
    "hash": "f810fd30917845ff934f7c6e23efdc5b50e9400772765ac0b00dcbae448bd04a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
